---
title: "Encelia Data"
---

## Motivation and Context

```{r}
#| label: do this first
#| echo: false
#| message: false

here::i_am("Project-Model-Selection-Encelia.qmd")
```

*Encelia californica* and *Encelia farinosa* are two bright yellow flowers that can be found in the Fullerton Arboretum. They can be used to restore deserts and native gardens and help with erosion control. It is important that people understand the differences between the two species if they are trying to restore areas and need the correct plant to do so. When restoring areas, it is important that the plant can flourish properly in the environment it is placed in. One of the biggest differences are when they flower. The *Encelia farinosa* flowers from February to May then August to September while *Encelia californica* flowers from February to October. Another difference is the elevations and locations where they thrive. *Encelia farinosa* can go up to 1000 meters above sea level and thrives in more inland desert regions, while the *Encelia californica* can go up to 600 meters above sea level and is found in more coastal regions.

The Fullerton Arboretum focuses on conserving and displaying the beauty of plants in a local community area. The Arboretum works with California State University, Fullerton to provide students with the ability to learn, research and appreciate these plants and horticulture.

## Main Objective

With this project, we are using a few main differences of these plants to build a model that can distinguish which plant is which based on a few basic measurements.

## Packages Used In This Analysis

```{r}
#| label: load packages
#| message: false
#| warning: false

library(here)
library(readr)
library(ggplot2)
library(dplyr)
library(rsample)
library(purrr)
library(yardstick)
library(tidyr)
library(tidyverse)
library(broom)
```

| Package | Use |
|------------------------------------|------------------------------------|
| [here](https://github.com/jennybc/here_here) | to easily load and save data |
| [readr](https://readr.tidyverse.org/) | to import the CSV file data |
| [dplyr](https://dplyr.tidyverse.org/) | to massage and summarize data |
| [ggplot2](https://ggplot2.tidyverse.org/) | to create nice-looking and informative graphs |
| [rsample](https://rsample.tidymodels.org/) | to split data into training and test sets |
| [purrr](https://purrr.tidyverse.org) | to run the cross-validation |
| [yardstick](https://yardstick.tidymodels.org) | to evalute the accuracy of the models |
| [tidyr](https://tidyr.tidyverse.org) | to "pivot" the predictions data frame so that each row represents 1 model |

## Design and Data Collection

As a class, we went to the Fullerton Arboretum and identified the two flowers that we wanted to collect the data on. We split into pairs and collected four pieces of data on the two species: the number of rays on each flower, the diameter of the center disk, the diameter of the entire flower, and the stem length. Everything was measured in centimeters. We used a simple measuring ruler and recorded our data on a sheet of paper. The number of rays was counted individually. The diameter of the disk was measured through the center from end to end. The diameter of the entire flower was measured similarly to the disk but extended to include the rays. The stem length was measured from the bottom of the flower part of the plant to the first area that it branched off closest to the flower. Each pair measured 10 flowers of each species, so in total we got 50 of each species.

![](https://cdn.discordapp.com/attachments/1331417272006217847/1372688761816616960/Flower_Description.png?ex=6827af88&is=68265e08&hm=70ae0f94d23d95902bbee85b7c30c235530d535600ba497477cef587d6c8a632&)

A few limitations of the data collection was limited access. There were many flowers that could not be accessed due to the desire to respect the grounds and not create new and unnatural paths. A lot of the flowers were also close to more dangerous plants like cacti or in areas that were fenced off, so that limited the randomness of the collection. My partner and I decided to stay consistent with who was collecting the data. Since we did this, we tried to limit the variation in measuring judgement that may have occurred had we not stayed consistent, like deciding where the center of a flower was. Additionally, the measurements that we did were not always as accurate as we wanted them. The rulers only went so far in the parts to a whole so judgement in rounding could be different based on who did the measuring.

## Training-Test Split

I'm going to read in the data and display it below.

```{r}
library(readr)
encelia <- read_csv("Data/Encelia Classification Data Collection - Sheet1.csv")
encelia <- encelia|>
  mutate(
    Species = Species |>
      as.factor()
  )

contrasts(encelia$Species)
```

The data consists of numeric values which are the measurements of each variable in centimeters or whole numbers for the ray count, so we do not need to change anything.

```{r}
#| label: This splits the data into training and test sets. 
set.seed(3)
encelia_split <- initial_split(
  encelia,
  strata = Species,
  prop = 0.80
)

encelia_train <- training(encelia_split)
encelia_test <- testing(encelia_split)

encelia_train$Species <- as.factor(encelia_train$Species)

#This creates the folds for later.
encelia_cv <- encelia_train |>
  vfold_cv(
    v=4, #4 fold cross-validation
    repeats = 1 #gives one unique prediction per observation in the training set
  )
```

A training set trains the model to be able to predict the outcome, and the test set will be put into the model to see how well it actually does predict. It will be useful for this objective because we want to build a model that can predict what species a flower is given the measurements. Additionally, I created the folds in the set that we can use to get the predictions.

## Exploratory Data Analysis

During the Logistic Regression with Encelia activity, we created plots that compared each of the variables to the species that it was. We knew that there were some differences to the flowers, and we were able to pinpoint the main identifiers that were different by comparing the two species. The graphs will help to identify which variables we should consider choosing for our model.

```{r}
#disk diameter vs. species
ggplot(
  data = encelia_train,
  mapping = aes(x = disk_diameter, y=Species)
  ) + 
  geom_jitter(height = 0.1)
```

The disk diameter is fairly similar for both flowers so it might not be as useful when creating our model. The model might get confused since there is not a significant difference.

```{r}
#number of rays vs. species
ggplot(
  data = encelia_train,
  mapping = aes(x = number_rays, y=Species)
  ) + 
  geom_jitter(height = 0.1)
```

We can see that the *Encelia californica* tended to have a higher number of rays than the *Encelia farinosa*, which is a known identifier for these species.

```{r}
#ray diameter vs. species
ggplot(
  data = encelia_train,
  mapping = aes(x = ray_diameter, y=Species)
  ) + 
  geom_jitter(height = 0.1)
```

The ray diameter seems very similar for both flowers, but the average for the *Encelia californica* was higher overall.

```{r}
#stem length vs. species
ggplot(
  data = encelia_train,
  mapping = aes(x = stem_length, y=Species)
  ) + 
  geom_jitter(height = 0.1)
```

Stem length for the *Encelia californica* had a wider range than the *Encelia farinosa.* With this knowledge, we could see that most of the *Encelia farinosa* had overall smaller stem lengths which could help us identify for our model.

After looking at these plots, we can see which variables might be the most important when helping our model predict the species. Before looking at the modeling, it seems like the stem length and ray diameter might be the biggest factors in predicting which species a flower is.

## Modeling

Logistic regression is a machine model that attempts to distinguish between categories and is used for prediction. The goal of our project is to be able to distinguish which flower is which so this model will help us do that.

Cross-validation is important to see how well the model works to predict what we want. It involves separating the data into training and testing sets. The training set trains the model using that data, and the testing set tests if the model really works how it should.

```{r}
#| label: build models 
encelia_prediction <- function(split) {

#Step 1: create the training and validation sets 
train <- analysis(split)
valid <- assessment(split)

#Step 2: Fit all the models on the training set
encelia_glm1 <- glm(Species ~ number_rays + disk_diameter + ray_diameter + stem_length, data = train, family = "binomial")
encelia_glm2 <- glm(Species ~ number_rays + ray_diameter + stem_length, data = train, family = "binomial")
encelia_glm3 <- glm(Species ~ disk_diameter + ray_diameter + stem_length, data = train, family = "binomial")
encelia_glm4 <- glm(Species ~ number_rays + disk_diameter + stem_length, data = train, family = "binomial")
encelia_glm5 <- glm(Species ~ number_rays + disk_diameter + ray_diameter, data = train, family = "binomial")
encelia_glm6 <- glm(Species ~ number_rays + stem_length, data = train, family = "binomial")
encelia_null <- glm(Species ~1, data = train, family = "binomial")

#Step 3: Make all the predictions on the validation set
valid_predictions <- valid |>
  mutate(
    pred_all = predict(encelia_glm1, newdata = valid, type = "response"), 
    pred_no_disk = predict(encelia_glm2, newdata = valid, type = "response"), 
    pred_no_rays = predict(encelia_glm3, newdata = valid, type = "response"),
    pred_no_diameter = predict(encelia_glm4, newdata = valid, type = "response"),
    pred_no_stem = predict(encelia_glm5, newdata = valid, type = "response"),
    pred_2 = predict(encelia_glm6, newdata = valid, type = "response"),
    pred_null = predict(encelia_null, newdata = valid, type = "response")
  )
return(valid_predictions)
}
```

```{r}
#This runs the function on the splits.
mapped_pred <- map(
  encelia_cv$splits, 
  encelia_prediction
)

mapped_pred_df <- mapped_pred |>
  bind_rows(
    .id = "fold"
  )

mapped_pred_df |>
  select(
    fold, Species, pred_all, pred_no_disk, pred_no_rays, pred_no_diameter, pred_no_stem, pred_2, pred_null
  )
```

```{r}
#Predictions in long form that we will eventually shorten
predictions <- mapped_pred_df |>
  pivot_longer(
    cols = starts_with ("pred"),
    names_to = "model",
    values_to = ".pred_F"
  ) |>
  mutate(
    .pred_C = 1 - .pred_F
  )

predictions |>
  select(
    model, fold, Species, .pred_C, .pred_F
  )
```

The code below will give us the average Brier score which we can use measure the accuracy of our predictions.

```{r}
brier_all_models <- predictions |>
  group_by(model, fold) |>
  brier_class(
    truth = Species,
    .pred_C
  )

brier_all_models |>
  ungroup() |>
  group_by(model) |>
  summarize(
    mean_brier = mean(.estimate),
    se_brier = sd(.estimate)/sqrt(4) #4 estimates
  ) |>
  arrange(mean_brier)
```

Based on the data collection, the factors I chose to put in my models seem to display the most differences between species. When creating the models, I wanted it to be able to predict as well as it could. I started with all of the predictors, then did different model with all of them but one. In this case, we want the model that has the lowest mean brier score, which was using all of the factors. Now, what we do is we fit the final model and test using that model.

```{r}
encelia_final_glm <- glm(Species ~ number_rays + disk_diameter + ray_diameter + stem_length, data = encelia_train, family = "binomial")
```

```{r}
encelia_prediction <- encelia_final_glm |>
  augment(newdata = encelia_test, type.predict = "response") |>
  mutate(
    .pred_F = .fitted,
    .pred_C = 1 - .pred_F,
    .pred_species = if_else(.fitted >= 0.5, "F", "C")|>
      as.factor()
  )

encelia_prediction |>
  select(Species, .pred_species, .pred_C, .pred_F)
```

## **Insights**

```{r}
encelia_prediction |>
  conf_mat(
    truth = Species, 
    estimate = .pred_species
  )
```

The confusion matrix above tells me if my model is predicting correctly. The ones that are in the place of having double of the letter (top left and bottom right) mean a correct prediction, while if they are in conflicting letter places (top right and bottom left), it is an incorrect prediction. My model is making pretty accurate predictions for the *Encelia farinosa* plant, but not as accurate predictions for the *Encelia californica* plant. The model got 14 out of 17 predictions correct.

There were three flowers that were incorrectly predicted. I think they might be incorrectly predicted because they had measurements that were abnormally like the *Encelia farinosa* plant rather than the rest of the *Encelia californica.* There was a lot of overlap in some of the measurements where it could have been a toss-up to which plant it was if they had not already been identified.
