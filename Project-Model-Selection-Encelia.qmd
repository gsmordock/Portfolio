---
title: "Encelia Data"
---

## Motivation and Context

```{r}
#| label: do this first
#| echo: false
#| message: false

here::i_am("Project-Model-Selection-Encelia.qmd")
```

*Encelia californica* and *Encelia farinosa* are two bright yellow flowers that can be found in the Fullerton Arboretum. They can be used to restore deserts and native gardens and help with erosion control. It is important that people understand the differences between the two species if they are trying to restore areas and need the correct plant to do so. When restoring areas, it is important that the plant can flourish properly in the environment it is placed in. One of the biggest differences are when they flower. The *Encelia farinosa* flowers from February to May then August to September while *Encelia californica* flowers from February to October. Another difference is the elevations and locations where they thrive. *Encelia farinosa* can go up to 1000 meters above sea level and thrives in more inland desert regions, while the *Encelia californica* can go up to 600 meters above sea level and is found in more coastal regions.

The Fullerton Arboretum focuses on conserving and displaying the beauty of plants in a local community area. The Arboretum works with California State University, Fullerton to provide students with the ability to learn, research and appreciate these plants and horticulture.

## Main Objective

With this project, we are using a few main differences of these plants to build a model that can distinguish which plant is which based on a few basic measurements.

## Packages Used In This Analysis

```{r}
#| label: load packages
#| message: false
#| warning: false

library(here)
library(readr)
library(ggplot2)
library(dplyr)
library(rsample)
library(purrr)
library(yardstick)
library(tidyr)
library(tidyverse)
library(broom)
```

| Package | Use |
|------------------------------------|------------------------------------|
| [here](https://github.com/jennybc/here_here) | to easily load and save data |
| [readr](https://readr.tidyverse.org/) | to import the CSV file data |
| [dplyr](https://dplyr.tidyverse.org/) | to massage and summarize data |
| [ggplot2](https://ggplot2.tidyverse.org/) | to create nice-looking and informative graphs |
| [rsample](https://rsample.tidymodels.org/) | to split data into training and test sets |
| [purrr](https://purrr.tidyverse.org) | to run the cross-validation |
| [yardstick](https://yardstick.tidymodels.org) | to evalute the accuracy of the models |
| [tidyr](https://tidyr.tidyverse.org) | to "pivot" the predictions data frame so that each row represents 1 model |

## Design and Data Collection

As a class, we went to the Fullerton Arboretum and identified the two flowers that we wanted to collect the data on. We split into pairs and collected four pieces of data on the two species: the number of rays on each flower, the diameter of the center disk, the diameter of the entire flower, and the stem length. Everything was measured in centimeters. We used a simple measuring ruler and recorded our data on a sheet of paper. The number of rays was counted individually. The diameter of the disk was measured through the center from end to end. The diameter of the entire flower was measured similarly to the disk but extended to include the rays. The stem length was measured from the bottom of the flower part of the plant to the first area that it branched off closest to the flower. Each pair measured 10 flowers of each species, so in total we got 50 of each species.

![](https://cdn.discordapp.com/attachments/1331417272006217847/1372688761816616960/Flower_Description.png?ex=6827af88&is=68265e08&hm=70ae0f94d23d95902bbee85b7c30c235530d535600ba497477cef587d6c8a632&)

A few limitations of the data collection was limited access. There were many flowers that could not be accessed due to the desire to respect the grounds and not create new and unnatural paths. A lot of the flowers were also close to more dangerous plants like cacti or in areas that were fenced off, so that limited the randomness of the collection. My partner and I decided to stay consistent with who was collecting the data. Since we did this, we tried to limit the variation in measuring judgement that may have occurred had we not stayed consistent, like deciding where the center of a flower was. Additionally, the measurements that we did were not always as accurate as we wanted them. The rulers only went so far in the parts to a whole so judgement in rounding could be different based on who did the measuring.

## Training-Test Split

I'm going to read in the data and display it below.

```{r}
library(readr)
encelia <- read_csv("Data/Encelia Classification Data Collection - Sheet1.csv")
```

The data consists of numeric values which are the measurements of each variable in centimeters or whole numbers for the ray count, so we do not need to change anything.

```{r}
#| label: This splits the data into training and test sets. 
set.seed(3)
encelia_split <- initial_split(
  encelia,
  strata = Species,
  prop = 0.80
)

encelia_train <- training(encelia_split)
encelia_test <- testing(encelia_split)
```

A training set trains the model to be able to predict the outcome, and the test set will be put into the model to see how well it actually does predict. It will be useful for this objective because we want to build a model that can predict what species a flower is given the measurements.

## Exploratory Data Analysis

**Expand on the EDA you did in the Logistic Regression with Encelia activity. Explain what is going on in your graphs and summaries and how those insights relate to the models you will be building in the next section.**

During the Logistic Regression with Encelia activity, we created plots that compared each of the variables to the species that it was. We knew that there were some differences to the flowers, and we were able to pinpoint the main identifiers that were different.

```{r}
#disk diameter vs. species
ggplot(
  data = encelia_train,
  mapping = aes(x = disk_diameter, y=Species)
  ) + 
  geom_jitter(height = 0.1)
```

The disk diameter is fairly similar for both flowers so it might not be as useful when creating our model. The model might get confused since there is not a significant difference.

```{r}
#number of rays vs. species
ggplot(
  data = encelia_train,
  mapping = aes(x = number_rays, y=Species)
  ) + 
  geom_jitter(height = 0.1)
```

We can see that the *Encelia californica* tended to have a higher number of rays than the *Encelia farinosa*, which is a known identifier for these species.

```{r}
#ray diameter vs. species
ggplot(
  data = encelia_train,
  mapping = aes(x = ray_diameter, y=Species)
  ) + 
  geom_jitter(height = 0.1)
```

The ray diameter seems very similar for both flowers, but the average for the *Encelia californica* was higher overall.

```{r}
#stem length vs. species
ggplot(
  data = encelia_train,
  mapping = aes(x = stem_length, y=Species)
  ) + 
  geom_jitter(height = 0.1)
```

Stem length for the *Encelia californica* had a wider range than the *Encelia farinosa.* With this knowledge, we could see that most of the *Encelia farinosa* had overall smaller stem lengths which could help us identify for our model.

After looking at these plots, we can see which variables might be the most important when helping our model predict the species. Before looking at the modeling, it seems like the stem length and ray diameter might be the biggest factors in predicting which species a flower is.

## Modeling

Logistic regression is a machine model that attempts to distinguish between categories and is used for prediction. The goal of our project is to be able to distinguish which flower is which so this model will help us do that.

Cross-validation is important to see how well the model works to predict what we want. It involves separating the data into training and testing sets. The training set trains the model using that data, and the testing set tests if the model really works how it should.

```{r}
#| label: build model with all predictors
#| 
encelia_train$Species <- as.factor(encelia_train$Species)

encelia_glm1 <- glm(
  Species ~ number_rays + disk_diameter + ray_diameter + stem_length,
  data = encelia_train, 
  family = "binomial"
)
encelia_glm1 |>
  tidy()
```

```{r}
#| label: build model without disk diameter
encelia_train$Species <- as.factor(encelia_train$Species)

encelia_glm2 <- glm(
  Species ~ number_rays + ray_diameter + stem_length,
  data = encelia_train, 
  family = "binomial"
)
encelia_glm2 |>
  tidy()
```

```{r}
#| label: build model without number of rays

encelia_train$Species <- as.factor(encelia_train$Species)

encelia_glm3 <- glm(
  Species ~ disk_diameter + ray_diameter + stem_length,
  data = encelia_train, 
  family = "binomial"
)
encelia_glm3 |>
  tidy()
```

```{r}
#| label: build model without ray diameter

encelia_train$Species <- as.factor(encelia_train$Species)

encelia_glm4 <- glm(
  Species ~ number_rays + disk_diameter + stem_length,
  data = encelia_train, 
  family = "binomial"
)
encelia_glm4 |>
  tidy()
```

```{r}
#| label: build model without stem length

encelia_train$Species <- as.factor(encelia_train$Species)

encelia_glm5 <- glm(
  Species ~ number_rays + disk_diameter + ray_diameter,
  data = encelia_train, 
  family = "binomial"
)
encelia_glm5 |>
  tidy()
```

```{r}
#| label: build model with ray count and stem length

encelia_train$Species <- as.factor(encelia_train$Species)

encelia_glm6 <- glm(
  Species ~ number_rays + stem_length,
  data = encelia_train, 
  family = "binomial"
)
encelia_glm6 |>
  tidy()
```

**Propose several logistic regression models and use cross-validation to select a best model, following the steps in the "Cross-Validation (Part 3)" video and the "Model Selection for Logistic Regression" activity.**

Based on the data collection, the factors I chose to put in my models seem to display the most differences between species. When creating the models, I wanted it to be able to predict as well as it could. I started with all of the predictors, then did different model with all of them but one.

-   **Which model are you selecting as the best model? Why?**

**Fit the selected "best" model on the training set and make predictions on the test set. Overall, how accurately is your model making predictions?**

## **Insights**

**Think about how you might visualize the model's predictions and the accuracy of those predictions. Then, create and describe one or more visualizations in line with your ideas.**

**Which flowers (if any) were incorrectly predicted? Why do you suspect that they were incorrectly predicted?**
