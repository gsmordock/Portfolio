---
title: "Project 1"
format: html
---

# Motivation and Context

For this project, I looked into the hospital dataset that we worked with throughout the semester. When we observed this data, the biggest questions I had in my head were these: how did we get to the final numbers of recommendation or overall score? Did certain aspects have more effects on the scores over others?

# Design and Data Collection

This dataset is a list of hospital rating for the Hospital Consumer Assessment of Healthcare Providers and Systems (HCAHPS), which is a survey for patients about their most recent hospital stay. The questions asked about many variables including: cleanliness, nurse communication, doctor communication, staff responsiveness, communication about medicine, discharge information, care transition, and quietness. These variables are the explanatory variable for our model. An overall score and a recommendation score was also collected, which will be our response variable for the model. These scores were collected in three different measurements: star ratings, linear mean scores, and with descriptions. The only scoring system that was a little difficult to understand was the star ratings. According to the data dictionary, "The Overall Star Ratings are designed to assist patients, consumers, and others in comparing hospitals side-by-side... The hospitals can receive between one and five stars, with five stars being the highest rating, and the more stars, the better the hospital performs on the quality measures."

This data was collected through a random sample of eligible discharges from a hospital. The eligibility includes:

-   at least 18 years of age at time of admission,

-   at least one overnight stay, and

-   non-psychiatric MS-DRG/principal diagnosis at discharge.

These patients were sampled randomly through telephone, IVR modes, and mail.

# Main Objective

My goal for this project is to see what factors are the heaviest influences on the overall and recommended scores that are reported using a linear regression model. I want to see which of the explanatory variables has the most impact.

While linear regression models are not always the best model that can be used to predict what factor has the highest influence on an outcome, I had been learning about them in Math 435 and wanted to combine that knowledge with coding to see what the outcome would be. A logistic regression model would have made much more sense for predicting as that is what they are mainly used for.

### My Process

The code below reads in the data as well as any packages that are necessary for the data cleaning I did.

```{r}
library(readr)
library(tidyverse)
library(janitor)
hospital <- read_csv("Data/hospital.csv", na=c("Not Applicable", "Not Available"))
```

We removed any of the data that said "Not Applicable" or "Not Available" and replaced it with a N/A that would help for further data analysis.

Below is the code that I used to only keep the pieces of data that I thought would be relevant to my project.

```{r}
hospital <- hospital |>
  select(
    `Facility ID`,
    `Facility Name`, 
    `HCAHPS Answer Description`, 
    `Patient Survey Star Rating`, 
     `HCAHPS Linear Mean Value`,
    `HCAHPS Answer Percent`,
    `Survey Response Rate Percent`,
    `Number of Completed Surveys`
  )
```

This renames the long descriptions and makes them shorter for easier coding in the future.

```{r}
hospital_clean <- hospital |>
  rename(
    answer = `HCAHPS Answer Description`,
    star_rating = `Patient Survey Star Rating`,
    mean_value = `HCAHPS Linear Mean Value`,
    answer_percent = `HCAHPS Answer Percent`,
    fac_id = `Facility ID`,
    fac_name = `Facility Name`, 
    response_rate = `Survey Response Rate Percent`,
    surveys = `Number of Completed Surveys`
  )
```

I want to group by rating system: star rating, linear mean value, and answer percent.

```{r}
hospital.star <- hospital_clean |>
  select(
    fac_id,
    fac_name, 
    answer, 
    star_rating, 
    response_rate,
    surveys
  )|>
  filter( 
    !is.na(star_rating)
  )

hospital.lmv <- hospital_clean |>
  select(
    fac_id,
    fac_name, 
    answer, 
    mean_value, 
    response_rate, 
    surveys
  )|>
  filter( 
    !is.na(mean_value)
  )

hospital.answer <- hospital_clean |>
   select(
    fac_id,
    fac_name, 
    answer, 
    answer_percent, 
    response_rate,
    surveys
  )|>
  filter( 
    !is.na(answer_percent))
```

This is trying to pivot wider so that we can visualize the data in a different way that is easier to read in columns rather than multiple rows.

```{r}
hospital.lmv <- pivot_wider(hospital.lmv, names_from = answer, values_from = mean_value)
hospital.answer <- pivot_wider(hospital.answer, names_from = answer, values_from = answer_percent)
hospital.star <- pivot_wider(hospital.star, names_from = answer, values_from = star_rating)
```

In looking at the data, the more specific data set would be the linear mean score, hence, I will be continuing to observe with just that data set.

The code below renames the pivoted variables to shorten them for further coding ease.

```{r}
hospital.lmv <- hospital.lmv |>
  rename(
      nurse_com = `Nurse communication - linear mean score`,
      doc_com = `Doctor communication - linear mean score`,
      staff_response = `Staff responsiveness - linear mean score`,
      med_coms = `Communication about medicines - linear mean score`, 
      discharge_info = `Discharge information - linear mean score`,
      care_transition = `Care transition - linear mean score`,
      clean = `Cleanliness - linear mean score`,
      quiet = `Quietness - linear mean score`,
      overall = `Overall hospital rating - linear mean score`,
      rec = `Recommend hospital - linear mean score`
  )

hospital.star <- hospital.star |>
  rename(
      nurse_com = `Nurse communication - star rating`,
      doc_com = `Doctor communication - star rating`,
      staff_response = `Staff responsiveness - star rating`,
      med_coms = `Communication about medicines - star rating`, 
      discharge_info = `Discharge information - star rating`,
      care_transition = `Care transition - star rating`,
      clean = `Cleanliness - star rating`,
      quiet = `Quietness - star rating`,
      overall = `Overall hospital rating - star rating`,
      rec = `Recommend hospital - star rating`
  )
```

This gets the average of the scores that could affect the overall or recommended score and creates a new column for that data point for each hospital.

```{r}
hospital.lmv <- hospital.lmv |>
  mutate( 
    average_score = rowMeans(subset(hospital.lmv, select = c(nurse_com, doc_com, staff_response, med_coms, discharge_info, care_transition, clean, quiet)), na.rm = TRUE)
  )
```

The code below finds the differences in the overall and recommendation scores versus the calculated average score.

```{r}
hospital.lmv <- hospital.lmv |>
  mutate(
    o.a = overall - average_score, 
    r.a = rec - average_score
  )
head(hospital.lmv)
```

The section above does not do too much for the initial goal of the project, but it is an interesting thing to see how the overall and recommended scores compare to the average that was calculated from the variables.

One thing I noticed was that the average was mostly lower than the overall score. Only 101 out of the 3197 entries had an average that was higher than the overall score. 19 entries had no difference in their average and overall score.

Now, what I want to find is which of the variables has the most impact on the recommended and overall scores, and I will do this through a multiple linear regression model.

This is my linear regression model for the given overall score using all of the factors.

```{r}
overall.lm <- lm(overall ~ nurse_com + doc_com +  staff_response + med_coms + discharge_info + care_transition + clean + quiet, data = hospital.lmv)

summary(overall.lm)
plot(overall.lm)
```

Below is my linear regression model for the given reccommended score using all of the variables.

```{r}

rec.lm <- lm(rec ~ nurse_com + doc_com + staff_response + med_coms + discharge_info + care_transition + clean + quiet, data = hospital.lmv)

summary(rec.lm)
plot(rec.lm)
```

In reading the summaries and looking at the residual plots, I noticed a few things:

Firstly, the linear model for the overall scores is generally a good fit. However, the recommendation score is not a great fit. There are four plots that we look at for determining if a linear model is a good fit. Those plots are Residuals vs. Fitted, Q-Q residuals, Scale-Location, and Residuals vs. Leverage. To make things short, we want certain shapes for each of these graphs to determine if the model is a good fit. For the Residuals vs. Fitted, Scale-Location, and Residuals vs. Leverage graphs, we want them generally to be scattered about a horizontal line. The Q-Q residuals is different in the sense that we want a diagonal line. For the Residuals vs. Leverage graph, we want our data to form a sort of cone shape that is limited by Cook's distance. Data that is outside that distance tends to skew the model. Notice how neither of the models really go past that line.

Secondly, there are a few data points that stick out and are labeled on the graphs. I did go back through the data to observe those, and they did have higher scores than anticipated, but I chalked it up to great experiences at the hospital.

Thirdly, we look at the r-squared values for each of the models in their summaries. Typically, the larger the value, the more precise the predictor variables are able to predict the overall or recommended score. With this knowledge, the overall linear model is a better model than the recommended model (0.8596 vs. 0.7812).

Lastly, I looked through the values for the predictive equation. The equations are as follows:

-   overall = -17.42 + 0.38(nurse_com) + 0.13(doc_com) + 0.03(staff_response) - 0.04(med_coms) + 0.04 (discharge_info) + 0.51(care_transition) + 0.10(clean) + 0.07(quiet)

-   rec = -49.96 + 0.51(nurse_com) + 0.16(doc_com) - 0.05 (staff_response) - 0.12(med_coms) + 0.03 (discharge_info) + 0.96(care_transition) + 0.08(clean) + 0.03(quiet)

I want to now take a few data points and test them on the models. I randomly selected 10 hospitals to use as my testers.

```{r}
hospital_testers <- sample(nrow(hospital.lmv), 10)
```

These numbers will be different each time the code is run, but when I sampled mine, the rows chosen were as follows:

```{r}
hospital_testers <- c(296, 190, 1857, 1686, 194, 1172, 2281, 1745, 97, 1226)

hospital_test <- hospital.lmv[hospital_testers,]
hospital_test
```

In trying to write a function that I could use to plug in the values, my code didn't seem to work, so I will be doing this the long way with plugging in the values individually. They will be organized by one word in the facility name as the name of the variable with an o or an r after depending on which prediction it is for.

#### Overall Predictions 

```{r}
providence.o = -17.42 + 0.38*92 + 0.13*90 + 0.03*85 - 0.04*74 + 0.04*87 + 0.51*82 + 0.10*88 + 0.07*75 
oroville.o = -17.42 + 0.38*82 + 0.13*84 + 0.03*68 - 0.04*65 + 0.04*78 + 0.51*71 + 0.10*75 + 0.07*66
university.o = -17.42 + 0.38*85 + 0.13*88 + 0.03*71 - 0.04*67 + 0.04*79 + 0.51*76 + 0.10*77 + 0.07*76 
columbia.o = -17.42 + 0.38*94 + 0.13*92 + 0.03*86 - 0.04*83 + 0.04*88 + 0.51*85 + 0.10*91 + 0.07*87 
olive.o = -17.42 + 0.38*89 + 0.13*90 + 0.03*78 - 0.04*75 + 0.04*87 + 0.51*80 + 0.10*85 + 0.07*74 
owensboro.o = -17.42 + 0.38*94 + 0.13*93 + 0.03*86 - 0.04*80 + 0.04*89 + 0.51*84 + 0.10*93 + 0.07*87 
southwestern.o = -17.42 + 0.38*88 + 0.13*88 + 0.03*83 - 0.04*73 + 0.04*84 + 0.51*78 + 0.10*87 + 0.07*85 
chadron.o = -17.42 + 0.38*91 + 0.13*97 + 0.03*89 - 0.04*85 + 0.04*90 + 0.51*81 + 0.10*87 + 0.07*90 
phoenix.o = -17.42 + 0.38*93 + 0.13*94 + 0.03*87 - 0.04*80 + 0.04*85 + 0.51*80 + 0.10*85 + 0.07*85 
louisville.o = -17.42 + 0.38*87 + 0.13*87 + 0.03*78 - 0.04*71 + 0.04*85 + 0.51*77 + 0.10*84 + 0.07*74 
```

| Hospital | Predicted Overall | Actual Overall |
|----------------------------------------|-----------------|---------------|
| Providence Holy Cross Medical Center | 88.18 | 90 |
| Oroville Hospital | 75.55 | 74 |
| The University Hospital | 80.71 | 81 |
| Columbia Mo Va Medical Center | 91.58 | 93 |
| LAC/Olive View-UCLA Medical Center | 85.4 | 86 |
| Owensboro Health Muhlenberg Community Hospital | 91.56 | 93 |
| Southwestern Medical Center | 84.82 | 86 |
| Chadron Community Hospital and Health Services | 88.95 | 90 |
| Phoenix Indian Medical Center | 88.2 | 90 |
| University of Louisville Hospital | 82.7 | 84 |

The predictions are very close to the actual score it received in this case.

#### Recommended Predictions

```{r}
providence.r = -49.96 + 0.51*92 + 0.16*90 - 0.05*85 - 0.12*74 + 0.03*87 + 0.96*82 + 0.08*88 + 0.03*75 
oroville.r = -49.96 + 0.51*82 + 0.16*84 - 0.05*68 - 0.12*65 + 0.03*78 + 0.96*71 + 0.08*75 + 0.03*66 
university.r = -49.96 + 0.51*85 + 0.16*88 - 0.05*71 - 0.12*67 + 0.03*79 + 0.96*76 + 0.08*77 + 0.03*76 
columbia.r = -49.96 + 0.51*94 + 0.16*92 - 0.05*86 - 0.12*83 + 0.03*88 + 0.96*85 + 0.08*91 + 0.03*87 
olive.r = -49.96 + 0.51*89 + 0.16*90 - 0.05*78 - 0.12*75 + 0.03*87 + 0.96*80 + 0.08*85 + 0.03*74 
owensboro.r = -49.96 + 0.51*94 + 0.16*93 - 0.05*86 - 0.12*80 + 0.03*89 + 0.96*84 + 0.08*93 + 0.03*87 
southwestern.r = -49.96 + 0.51*88 + 0.16*88 - 0.05*83 - 0.12*73 + 0.03*84 + 0.96*78 + 0.08*87 + 0.03*85 
chadron.r = -49.96 + 0.51*91 + 0.16*97 - 0.05*89 - 0.12*85 + 0.03*90 + 0.96*81 + 0.08*87 + 0.03*90 
phoenix.r = -49.96 + 0.51*93 + 0.16*94 - 0.05*87 - 0.12*80 + 0.03*85 + 0.96*80 + 0.08*85 + 0.03*85 
louisville.r = -49.96 + 0.51*87 + 0.16*87 - 0.05*78 - 0.12*71 + 0.03*85 + 0.96*77 + 0.08*84 + 0.03*74 
```

| Hospital | Predicted Recommended | Actual Recommended |
|----------------------------------------|----------------|----------------|
| Providence Holy Cross Medical Center | 88.85 | 88 |
| Oroville Hospital | 72.58 | 69 |
| The University Hospital | 79.65 | 79 |
| Columbia Mo Va Medical Center | 92.57 | 92 |
| LAC/Olive View-UCLA Medical Center | 85.36 | 86 |
| Owensboro Health Muhlenberg Community Hospital | 92.32 | 91 |
| Southwestern Medical Center | 83 | 85 |
| Chadron Community Hospital and Health Services | 87.44 | 91 |
| Phoenix Indian Medical Center | 87.26 | 86 |
| University of Louisville Hospital | 81.32 | 82 |

The recommended score has a little bit more range to the predictions.

# Conclusion

I was curious about what variable impacts the scores the most. With these equations, there is a heavy influence from the care transition for both models as it has the highest coefficient, and therefore influence when calculating the final score.

Both linear models have pretty accurate predictions with occasional variation when tested with a random sample of hospitals.

# Limitations

If I were to receive this data to help me choose a hospital to go to, I would rely more on the overall scores model to help me make my decision over the recommended score. However, this data should not be the only research done for these hospitals. These models do not always account for every different experience that a person would get, and some may be skewed positive or skewed negative experiences. The response rates for each of the hospitals varies incredibly, which can also be a factor in what data they receive. In looking at the data collection process, it seems that most of the surveys were of a voluntary response, indicating that mostly those who are passionate about their experience will respond. This may not be truly random data and should be taken with a grain of salt. If used in the real world, the model would affect those who were trying to make a decision on what hospital they should use. If someone tried to choose the best hospital and got one that had more skewed results, they might not get the standard of care that they anticipated which could lead to a worse experience. It could also very much rule out great hospitals that got bad reviews from some unfortunate experiences. With this, certain hospitals could get over-crowded if there are a lot of good reviews rating them higher. This in turn could cause for more bad reviews as people wait longer for their care. Overall, this model could have a lot of influence on how these hospitals perform and how the people going to these hospitals could receive their care.
